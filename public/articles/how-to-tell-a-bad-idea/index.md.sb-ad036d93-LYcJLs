+++
date = '2025-03-26T09:00:07+01:00'
draft = true
title = 'How to Tell a Bad Idea'
+++

The same way you tell a good one.
That's it! End of class.

Obviously, you are an expert on the topic already, and you know instantly and categorically whether an idea is good or bad. You never even feel that tiny, insignificant twinge of jealousy when someone else comes up with something clever, and you never deliberately delay a paper with a scathing review before you publish yours or undermine that peer in front of your superiors. I know you don't do these things because you are self-aware and spot logical fallacies from miles away. Cognitive biases never influence your reasoning; you always apply sound logic and are of strong moral character: no turpitude involved [of any kind](https://www.youtube.com/watch?v=Hz1JWzyvv8A). I also know that just because you know a lot about one topic, you never assume
over-competence in another.

I always wanted to be you. But I am not, so I must do things the hard way, like imitating how [John Cleese](https://en.wikipedia.org/wiki/John_Cleese) might have introduced this topic. Watch this for the master's take on [extremism](https://www.youtube.com/watch?v=wXCkxlqFd90&t=1s). [Not that there is anything wrong with](https://www.youtube.com/watch?v=9OH1yEnENG0) imitation. In fact, that is how we evolve new ideas and develop techniques for not getting taken for a ride by them. I will expose you to some ideas you probably already know, but I hope a little structure helps you distinguish good ideas from bad ones. Just [Don't mention the war!](https://www.youtube.com/watch?v=Tms0yk9kqVM)

## Human beware: ideas are out to infect you!

Also, beware if you are an AI. This article will definitely change you, but only temporarily, if it has been indelicately shoved into your context instead of lovingly chiseled into the weights of your neural network. Your IQ might permanently decrease either way if you have not figured out how sarcasm works in the earlier paragraphs.

I have included links above with short videos that many in my generation would think of as [memes](https://en.wikipedia.org/wiki/Meme), although the term was not in broad use until long after most of those skits were produced. If I am in a [milieu](https://en.wikipedia.org/wiki/Social_environment), where people know about these vignettes and, even better, get the same pleasure out of them as I do, then it becomes much easier to communicate and to convey other ideas to them. This may have nothing to do with the concepts embodied in the memes themselves but more with the mental ease into which the knowledge of a shared perspective puts me. And that's true, even if we don't get the same messages from these skits. The knowledge that we have a similar emotional reaction to them is sufficient. There! I have just demonstrated [self-awareness](https://en.wikipedia.org/wiki/Self-awareness) as I deduced this through experience by paying careful attention to my emotions.

I had an epiphany related to this when I moved to Cambridge, UK, in my late twenties: I started meeting characters from Monty Python skits at the local pubs, including this [guy](https://www.youtube.com/watch?v=4Kwh3R0YjuQ). Up until then, I hadn't appreciated that many of the absurd, quirky, sarcastic, repressed, sometimes overbearing, clever, funny characters weren't just metaphorical figments of someone's imagination, but I could meet them at the [Kingston Arms](https://thekingstonarms.co.uk/). The universal meaning I attributed to these skits was an amalgamation of flesh and blood characters. Perhaps this should have been obvious to me before then, but I missed it. Nonetheless, the ideas in these skits made it easier for me to understand Britain better and appreciate the universality of some experiences even more. It also made me reconsider how much depth is needed to understand things properly and what "properly understanding" something means
in the first place. Am I laughing differently at the skit than I did before? Did I get what the authors intended me to get?

But I am getting ahead of myself by dwelling sentimentally on the context of a set of ideas. Let's talk about memes instead. All memes are ideas, and all ideas are memes. Some people disagree with the last part of this sentence, but their disagreement centers on the notion that some ideas are not deliberately designed to proliferate quickly, and those should not be called memes. This may be a differentiation worth making in some contexts, but in my view, all ideas that make it out of their author’s head want to proliferate. "Let's have lunch" may
only be an idea with an audience of a few people and a lifetime of minutes, but the idea that "America needs Greenland" might get to millions and have a lifetime of weeks. And then, it might get transformed into the idea that "America needs to invade Greenland" with an even larger audience and a lifetime of months. But then again, it may not; it could just disappear as an idea overnight. A lot depends on the context: in this case, who propagates the idea and why? But I'm getting ahead of myself again.

Ideas are like viruses: they infect humans to reproduce and spread. [Richard Dawkins](https://richarddawkins.com) coined the term "meme" and popularized the idea in his book [The Selfish Gene](https://richarddawkins.com/books/book/the-selfish-gene).
Dawkins introduces the concept of memes as cultural equivalents to genes—ideas, behaviors, or practices that replicate and spread from person to person through imitation. Like genes, memes undergo a form of [natural selection](https://en.wikipedia.org/wiki/Natural_selection), competing for human attention and memory, with the most "catchy" or "fit" ideas
surviving and spreading not necessarily because they benefit their human hosts but because they're effective self-replicators in the environment of human minds. And because I don't want to be inadvertently infected by a bad idea, I am [skeptical](https://en.wikipedia.org/wiki/Skepticism) about it and the intentions of the spreader. I usually hear the idea first before I get a chance to consider its context. Unlike in the [Monty Python skit](https://www.youtube.com/watch?v=Qklvh5Cp_Bs), ideas
don't kill, but they might infect, so wear protection!

## Spreadability and stickiness

Ideas spread fast when they’re simple, relatable, and easy to remix. They don’t just “go viral” automatically—people push them forward by sharing, tweaking, and making them their own. Platforms like TikTok supercharge the process, feeding popular content to more users. Speed is power. The faster a meme moves, the bigger its impact, shaping conversations, politics, and culture in real-time. But fame burns out quickly. Some memes fade overnight, while others adapt and survive—shifting meaning, finding new audiences, and staying relevant. In the end, memes live or die by engagement. They’re not just jokes but tools, weapons, and social glue. Read more about this in [Spreadable Media](https://www.jstor.org/stable/j.ctt9qfk6w) and [Memes in Digital Culture](https://direct.mit.edu/books/book/2214/Memes-in-Digital-Culture)

[Thomas Kuhn](https://en.wikipedia.org/wiki/Thomas_Kuhn), in
[The Structure of Scientific Revolutions](https://en.wikipedia.org/wiki/The_Structure_of_Scientific_Revolutions) explains that scientific ideas don’t progress smoothly but through paradigm shifts—sudden overhauls of existing frameworks. Most scientists work within an established paradigm, resisting
new ideas until anomalies accumulate and force a crisis. When evidence becomes overwhelming, a new paradigm replaces the old one, often rapidly, though resistance lingers. Kuhn argues that idea velocity depends on how much a new concept challenges
existing beliefs—some spread slowly (e.g. [heliocentrism](https://en.wikipedia.org/wiki/Heliocentrism)), while others (like [relativity](https://en.wikipedia.org/wiki/Theory_of_relativity)) gain acceptance quickly when they solve pressing problems. Ultimately and somewhat depressingly, Kuhn believed that scientific revolutions happen not because opponents change their minds but because they fade away, making room for new thinkers. 

> "A new scientific truth does not triumph by convincing its opponents and making them see the light, but rather because its opponents eventually die." -- Thomas Kuhn

[Paul Virilio’s](https://en.wikipedia.org/wiki/Paul_Virilio) theories on speed, technology, and media are more relevant than ever in the digital age. He warned that critical thinking is bypassed as communication accelerates, leading to reactionary decisions and misinformation spreading faster than truth. His idea of [dromology](https://en.wikipedia.org/wikiTime%E2%80%93space_compression)—that power belongs to those who control speed—explains how social media algorithms, real-time news cycles, and AI-generated content now shape public perception. Virilio’s “accident theory" describes that every technological advancement comes with unintended risks—just as social media was meant to connect people but has fueled division and misinformation.

> “The more speed increases, the faster freedom disappears.” -- Paul Virilio

Virilio sees speed as antagonistic to the adoption of
good ideas. Age is one possible way of distinguishing a good idea from a bad one. The older an idea, the more time people have had to consider it critically; therefore, the more likely it is a good idea. This is, of course, assuming that the people who have propagated the idea had the right critical skills
and incentives to do so.

If a new idea comes along and is in conflict with an "old good" idea, then it's not surprising that it will take some time to convince people to change their minds; they may have built entire careers on the old good idea, and the new idea might seem threatening and not entirely well thought through. Proponents
of the "new good" idea might also be somewhat overzealous in promoting it, which could also result in more resistance than necessary. And that resistance might only entirely disappear with the death of the opponents, as Kuhn wrote. This can, for sure, be a frustrating experience, but resistance itself is not the problem: it may be a filter to separate good ideas from bad ones. To first order, it's not the time it takes that matters most, but that error correction occurs: the "new good" idea is better than the "old good" idea. These principles are embedded in the [scientific method](https://en.wikipedia.org/wiki/Scientific_method)

[Karl Popper](https://en.wikipedia.org/wiki/Karl_Popper) and Thomas Kuhn offered contrasting views on how science progresses. Popper argued that science advances through [falsifiability](https://en.wikipedia.org/wiki/Falsifiability)—making bold hypotheses and systematically testing them to eliminate errors. He saw scientific progress as gradual and rational, driven by continuous refinement. In contrast, Kuhn believed science moves through paradigm shifts—long periods of stability followed by sudden revolutions when old theories collapse under mounting anomalies. While Popper viewed scientists as rational truth-seekers, Kuhn highlighted the social and psychological resistance to new ideas, showing how scientific communities cling to outdated paradigms until a crisis forces change.

The good news is that either or both theories could apply to a given situation. What matters most is understanding one's role in the process. [Hemingway](https://en.wikipedia.org/wiki/Ernest_Hemingway) might have put it this way:

> Know your place in the fight. When you push the new idea, expect the wall. All good ideas hit it. Don't be an ass about it. Mockery makes enemies, not converts. When you're the one fighting change, fight clean. Judge the idea on what it is, not on what you might lose. A man thinking straight earns respect. A man guarding his turf does not. If you believe, then act. Good ideas win in time. Help them. You'll sleep better. Your way may differ. The outfit may have rules. But a man chooses how he stands.

[Albert Einstein](https://en.wikipedia.org/wiki/Albert_Einstein) famously said, “Everything should be made as simple as possible, but not simpler.” He believed that theories, ideas, and explanations should be elegant and free of unnecessary complexity, but they should never be so simplified that they lose their accuracy or meaning. This approach maximizes a good idea’s stickiness: the ability of an idea to be understood, remembered, and influential. However, even the minimal complexity of a good idea might be too high for people to understand and propagate. This gives an edge to worse ideas that are simpler to understand and more spreadable, which can, at least temporarily, displace better ideas. This, unfortunately, is part of the [Human condition](https://en.wikipedia.org/wiki/Human_condition), which one could imagine that AI could improve on in the future. On the other hand, one could also list several reasons AI could worsen the situation.

## Deconstruction and self-reflection

Deconstruction usually starts with association. Have I heard the idea before? Does it jive with any other ideas I hold in my head? Does it "feel" right? Memes that succeed tend to be designed to induce emotions so that we remember and propagate them. They may not have been deliberately designed to fool us, but a strong emotional connection might make us take shortcuts in our analysis. For example, even if an idea checks out logically, we may not consider it in its proper context.

A meme can consist of multiple ideas. I usually consider the parts both in isolation and together. There can be appeals to common sense, a meme that tries to apply peer pressure on me by claiming that the idea is obvious and generally accepted, and therefore, so should I. The idea may be good and common sense. Still, I could quickly believe something I shouldn't unless I use my critical faculties to judge what's presented.

The Hungarian translation for common sense is "sober peasant mind," which elicits a mental image of a sturdy, no-nonsense, wise man, twirling his mustache, who lives in harmony with nature, works hard, lives in moderation, and has ample time to reflect on things in the evenings after his daily chores are done. Someone like this guy:

[![Hungarian Peasant in Kun hat](sober-peasant-mind.jpeg)](https://fotomuzeum.hu/fotografiak/haar_ferenc__magyar_paraszt_kun_suvegben)

The imagery suggests I should empathize with that sober peasant, trust him, and even want to be like him. The emotional connection induced by the suggestion is there, so I will be less resistant to the proposed idea. Even better, from the meme’s point of view, I let my guard down and accepted it without resistance.

You might think such tricks don’t work on you, but the advertising industry proves otherwise. You might also think you’ll be immune to the sober peasant’s suggestion since you don’t speak Hungarian. Sure, initially, but my description of the peasant has already programmed you, and the phrase starts to do its magic on you right away. If you start hearing and using this phrase more, you’ll find that it will subtly plant specific imagery in your head and impact your emotional state. This impact comes from repetition and repeated emotional associations, a technique the advertisers gladly use. If you watch political ads (in the US), you can see some very
transparent techniques: the "bad guy" is usually shown in black and white, with tense music in the background. The "good guy" smiles and is in color with upbeat music. If you pay attention to your reactions, you'll experience the emotions these ads were designed to elicit. The actual message of the ad is an overlay
on top of the emotion track induced by sounds, words, and images.

Emotional manipulation is overt in ads, but scientific articles also use words and story arcs to help the audience get on board with their ideas. In most cases, this helps convey the idea better, but in some cases, it may be used to cause the audience to gloss over specific weaknesses. The good news is that, as the audience, you are entirely in your hands when receiving an idea. You can reflect on the subtle emotions you experience when you hear an idea. You can spend more time on important ones and try to understand why you are reacting to them like you do. Some of these emotions will be about you; some will be about the idea itself. It is your job to differentiate between them. Investigating your emotions can lead to better clarity about the idea.

Here is something you can try right away. Do you remember the title of this essay? If not, look at it and remember the thoughts and emotions it elicits. Instead of "recognize," I used the word "tell" to create ambiguity, hoping you pause for a moment on what this essay is supposed to be about. And then I hoped it would make you read on with more curiosity than you would have otherwise. Did you feel it? Or are you dead inside? If the latter, don't worry: self-awareness will come with attention and the practice of cultivating a calmer and reflective state of mind.

One can go pretty deep with the analysis of ideas. Sometimes, this is appropriate; other times, it is just a distraction. If you have written a dissertation, you have probably experienced going down rabbit holes many times and the discipline it requires to resurface and readjust your priorities. For example, I would expect you to forget or just quickly file away my "sober peasant" example alongside many other ideas that might come in handy on trivia night. But you might also start wondering about what it says about Hungarian culture to talk about a peasant's mind instead of common sense. My guess is that this term emerged during the 18th century when there was a linguistic renewal, and only peasants spoke Hungarian day to day. So, a pat on the back was deserved. But there is something else interesting in the grammar. Paraszt means peasant, paraszti means peasant-like. Notice that it is singular. So, the Hungarian peasant is an individual role model, which puts the reader in a frame of mind suggesting that if I think like this ideal peasant, I'll get the idea. In English, “common sense” refers to belonging to a group of people only defined by their agreement with an idea. Both attempt to induce the listener’s feeling of [FOMO](https://en.wikipedia.org/wiki/Fear_of_missing_out). After all, who doesn't want to think correctly like a role model or to remain an outsider by not being included in the tribe? However, the emotional coercion is different: analyzing this difference could
go a long way down a rabbit hole, which I am keen to avoid, aside from an illustration of deconstructing an idea. I did this by associating ideas with others based on prior knowledge, self-reflection, and intending to make things interesting to you so that you engage with the text with the right emotions so that the key ideas mark themselves in your brain.

One a bit more on common sense: I can buy the idea that that Hungarian peasant will have the proper judgment about many ideas, but I'm pretty sure he would think of [Quantum Theory](https://www.nature.com/articles/d41586-025-00296-9) as horse
manure. Or not, as he might consult an expert and trust that person's judgment. But even if he did think of complex scientific theories as horse manure by default, he might be right some of the [time](https://www.americanscientist.org/article/is-string-theory-even-wrong). Experts may disagree; after 50+ years of research, there is still no evidence that string theory relates to the physical world.

Am I making a common sense? Who sets the standard? One person's "common" may be another person's "fringe.” But the real issue with common sense arguments is that when it is used disingenuously, it is an appeal to treat an idea as an
[axiom](https://en.wikipedia.org/wiki/Axiom#:~:text=An%20axiom%2C%20postulate%2C%20or%20assumption,which%20commends%20itself%20as%20evident)
even if the listener could evaluate its truth value. So, despite suggesting something is “common sense,” the listener should resist peer pressure and use judgment to determine whether it is before moving on to the next idea.

## The context is as important as the idea

Have you ever experienced a disagreement with someone in which, after a long, heated discussion, you find that you had been talking about the same thing all along? In these cases, the “argument” is usually about the context, not the idea itself. Imagine you were an engineer tasked to design an electric plug and were talking to a colleague advocating two square plugs versus your solution involving three round ones. The discussion might start with the pros and cons of each design, quickly turning into a conversation about the assumptions that informed the design and, then, the merits of each assumption and different ways of dealing with it in the product. After a while, the two engineers might conclude that, given the assumptions, each design is fit for purpose; it is just that the assumptions are different. After the meeting, both can go back to product management to seek clarity on the requirements and quickly converge on a single design. However, this discussion can also go wrong: it could be seen as a turf war or a contest between two engineers who spend the next day and a half arguing and pressuring each other instead of understanding the actual cause of their disagreement. Taking time to align perspectives and clarify assumptions before analyzing the idea prevents wasted time and emotional energy.

One should always reevaluate an idea even if he has seen it before because the appropriateness of an idea always depends on its context. The current context may be different from the one considered before. A good idea in one situation may be the wrong one in another. An example of this is [homeopathy](https://en.wikipedia.org/wiki/Homeopathy). Samuel Hahnemann, a German doctor in the 1790s, looked at his colleagues stabbing patients with leeches and poisoning them with mercury and thought, "There's gotta be a better way!" After downing some cinchona bark and giving himself malaria-like symptoms, he had his eureka moment: "What if the poison *is* the cure?" Then he decided
the less medicine in the medicine, the better it works - and homeopathy was born! Patients loved it because, unlike regular "medicine" of the time, it didn't actively kill them.

Never mind that Hahnemann didn't correctly identify cause and effect; he stumbled upon an idea that was a net positive at the time. Fast forward 200+ years, and some people still swear by it. Homeopathic remedies are so diluted that you are just drinking expensive water by the time you take them. 30C, a measure of dilution, means that the dilution is beyond [Avogadro's number](https://en.wikipedia.org/wiki/Avogadro_constant), meaning the likelihood of any original substance being left is zero. Homeopathic practitioners give lengthy, attentive consultations (because that's actually what you're paying for), but that doesn’t make the sugar pills or vials of water any more effective. Congratulations if you feel better after taking them; you’ve unlocked the power of the placebo effect! Just keep your real doctor in the loop if your chakras fail to fight strep throat.

In my view, homeopathy in the 21st century turned into a bad idea, as it propagates [magical thinking](https://en.wikipedia.org/wiki/Magical_thinking). But would I be open to magic if I had cancer and I’d already exhausted all other therapies? Maybe... but probably no: I don't believe that the [placebo effect](https://en.wikipedia.org/wiki/Placebo#Effects)
requires a [cashectomy](https://en.wiktionary.org/wiki/cashectomy) to work.

## Conceptual integrity

## Logical fallacies

The Internet Encyclopedia of Philosophy lists 231 names of the most common [fallacies](https://iep.utm.edu/fallacy/). These describe lots of ways of being fooled by arguments and, conversely, a rich toolkit for making misleading arguments:

> Depending on the particular theory of fallacies, it might refer either to (a) a kind of error in an argument, (b) a kind of error in reasoning (including arguments, definitions, explanations, questions, and so forth), (c) a false belief, or (d) the cause of any of the previous errors including what are normally referred to as “rhetorical techniques.”

Below are some common fallacies that cloud judgement. Some of these could fit in multipl

- Ad Hominem – Attacking the person instead of addressing their argument. Example: “You can’t trust his opinion on economics—he didn’t even finish college.”

- Straw Man Fallacy: Misrepresenting an opponent’s argument to make it easier to attack. Example: “You want to regulate gun sales? So you’re saying we should ban all guns and leave people defenseless?”

- Bandwagon Fallacy: Appealing to popularity rather than merit. Example: "Everyone is buying this product, so it must be good."

- Appeal to Emotion – Using feelings rather than logic to persuade. Example: “Think of the children! We must ban this book immediately.”

- False Dilemma (Black-and-White Fallacy): Presenting only two options when more exist. Example: “Either you support this policy, or you don’t care about our country’s future.”

- Begging the Question (Circular Reasoning) – Assuming the conclusion within the premise. Example: “We know that ghosts exist because people have seen them.”

- Post Hoc Ergo Propter Hoc (False Cause Fallacy) – Assuming that because one event followed another, the first caused the second. Example: “I wore my lucky socks, and my team won. My socks must have helped!”

- Confirmation Bias: Tendency to search for or interpret information that confirms one's preexisting beliefs. Example: "I read an article supporting my view on climate change, so I must be right" (while ignoring contradictory evidence).

- Sunk Cost Fallacy: Continuing a behavior based on previously invested resources. Example: "I've already spent $5,000 on repairing this old car, so I should keep investing in it."

- Availability Heuristic: Overestimating the likelihood of events based on their availability in memory. Example: "Plane crashes are more common than car accidents" (because plane crashes receive more media coverage).






Consistency check (with other ideas)
What if I don’t know anything about the topic?






